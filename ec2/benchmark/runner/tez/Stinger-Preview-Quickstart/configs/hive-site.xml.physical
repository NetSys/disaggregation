<configuration>
    <property>
    <name>hive.semantic.analyzer.factory.impl</name>
    <value>org.apache.hivealog.cli.HCatSemanticAnalyzerFactory</value>
  </property>
    <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>XXX</value>
  </property>
    <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>XXX</value>
  </property>
    <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>XXX</value>
  </property>
    <property>
    <name>hadoop.clientside.fs.operations</name>
    <value>true</value>
  </property>
    <property>
    <name>hive.metastore.execute.setugi</name>
    <value>true</value>
  </property>
    <property>
    <name>hive.security.authorization.manager</name>
    <value/>
  </property>
    <property>
    <name>hive.metastore.uris</name>
    <value>XXX</value>
  </property>
    <property>
    <name>hive.metastore.client.socket.timeout</name>
    <value>60</value>
  </property>
    <property>
    <name>fs.hdfs.impl.disable.cache</name>
    <value>true</value>
  </property>
    <property>
    <name>hive.security.authorization.enabled</name>
    <value>false</value>
  </property>
    <property>
    <name>hive.metastore.cache.pinobjtypes</name>
    <value>Table,Database,Type,FieldSchema,Order</value>
  </property>
    <property>
    <name>hive.server2.enable.doAs</name>
    <value>true</value>
  </property>
    <property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/apps/hive/warehouse</value>
  </property>
    <property>
    <name>hive.metastore.local</name>
    <value>false</value>
  </property>
    <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
  </property>
  <property>
    <name>hive.enforce.bucketing</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.enforce.sorting</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.map.aggr</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.optimize.bucketmapjoin</name>
    <value>false</value>
  </property>
  <property>
    <name>hive.optimize.bucketmapjoin.sortedmerge</name>
    <value>false</value>
  </property>
  <property>
    <name>hive.mapred.reduce.tasks.speculative.execution</name>
    <value>false</value>
  </property>
  <property>
    <name>hive.auto.convert.join</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.auto.convert.sortmerge.join</name>
    <value>false</value>
  </property>
  <property>
    <name>hive.auto.convert.sortmerge.join.noconditionaltask</name>
    <value>false</value>
  </property>
  <property>
    <name>hive.auto.convert.join.noconditionaltask</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.auto.convert.join.noconditionaltask.size</name>
    <value>64000000</value>
  </property>
  <property>
    <name>hive.optimize.reducededuplication.min.reducer</name>
    <value>1</value>
  </property>
  <property>
    <name>hive.optimize.mapjoin.mapreduce</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.stats.autogather</name>
    <value>true</value>
  </property>
  <property>
    <name>mapred.reduce.parallel.copies</name>
    <value>30</value>
  </property>
  <property>
    <name>mapred.job.shuffle.input.buffer.percent</name>
    <value>0.5</value>
  </property>
  <property>
    <name>mapred.job.reduce.input.buffer.percent</name>
    <value>0.2</value>
  </property>
  <property>
    <name>mapreduce.map.output.compress</name>
    <value>true</value>
  </property>
  <property>
    <name>mapreduce.map.output.compress.codec</name>
    <value>org.apache.hadoop.io.compress.SnappyCodec</value>
  </property>
  <property>
    <name>tez.runtime.intermediate-output.should-compress</name>
    <value>true</value>
  </property>
  <property>
    <name>tez.runtime.intermediate-output.compress.codec</name>
    <value>org.apache.hadoop.io.compress.SnappyCodec</value>
  </property>
  <property>
    <name>tez.runtime.intermdiate-input.is-compressed</name>
    <value>true</value>
  </property>
  <property>
    <name>tez.runtime.intermediate-input.compress.codec</name>
    <value>org.apache.hadoop.io.compress.SnappyCodec</value>
  </property>
  <property>
    <name>hive.input.format</name>
    <value>org.apache.hadoop.hive.ql.io.HiveInputFormat</value>
  </property>
  <property>
    <name>hive.orc.splits.include.file.footer</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.root.logger</name>
    <value>ERROR</value>
  </property>
  <property>
    <name>hive.optimize.tez</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.vectorized.execution.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>hive.compute.query.using.stats</name>
    <value>true</value>
  </property>
  <property>
    <name>mapreduce.map.memory.mb</name>
    <value>4096</value>
  </property>
  <property>
    <name>mapreduce.reduce.memory.mb</name>
    <value>4096</value>
  </property>
  <property>
    <name>mapred.map.child.java.opts</name>
    <value>-server -Xmx3500m -Djava.net.preferIPv4Stack=true</value>
  </property>
  <property>
    <name>mapred.reduce.child.java.opts</name>
    <value>-server -Xmx3500m -Djava.net.preferIPv4Stack=true</value>
  </property>
</configuration>
